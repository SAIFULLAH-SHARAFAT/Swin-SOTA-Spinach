import os
import gc
import random
import json
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, WeightedRandomSampler
from torchvision import datasets, transforms
from sklearn.metrics import (
    classification_report, confusion_matrix, f1_score, roc_auc_score,
    accuracy_score, balanced_accuracy_score
)
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import timm
from torch.cuda.amp import autocast, GradScaler
from timm.data.mixup import Mixup
import datetime
import logging

# ---------------------------- Configuration ----------------------------
class Config:
    DATA_PATHS = {
        "train": "/kaggle/input/minida/mini_output1/train",
        "val":   "/kaggle/input/minida/mini_output1/val",
        "test":  "/kaggle/input/minida/mini_output1/test"
    }
    CLASS_NAMES = sorted(os.listdir(DATA_PATHS["train"]))
    NUM_CLASSES = len(CLASS_NAMES)
    MODEL_NAME = "swinv2_small_window16_256"
    IMG_SIZE = 256
    DROP_RATE = 0.2
    DROP_PATH_RATE = 0.2
    USE_MIXUP = True
    MIXUP_ALPHA = 0.3
    CUTMIX_ALPHA = 1.0
    USE_TTA = True      # Toggle test-time augmentation
    ACCUM_STEPS = 2
    TRAIN_BATCH_SIZE = 32 // ACCUM_STEPS
    VAL_BATCH_SIZE = 64
    EPOCHS = 40
    LR = 1e-4
    WEIGHT_DECAY = 0.05
    LABEL_SMOOTHING = 0.1
    CONTRASTIVE_LOSS_WEIGHT = 0.3   # Weight for supervised contrastive loss (0 = disable)
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    NUM_WORKERS = 2
    MIXED_PRECISION = True
    OUTPUT_DIR = "./output"
    MODEL_SAVE = f"./output/best_swinv2.pth"
    EARLY_STOP_PATIENCE = 7
    GRAD_CLIP = 1.0
    LOG_FILE = "training.log"
    def __init__(self):
        os.makedirs(self.OUTPUT_DIR, exist_ok=True)
        self._set_seed()
        self._set_timestamp()
        self._setup_logging()
    def _set_seed(self):
        torch.manual_seed(42)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(42)
        np.random.seed(42)
        random.seed(42)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
        os.environ["PYTHONHASHSEED"] = "42"
    def _set_timestamp(self):
        self.TIMESTAMP = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    def _setup_logging(self):
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        if not self.logger.handlers:
            file_handler = logging.FileHandler(os.path.join(self.OUTPUT_DIR, self.LOG_FILE))
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)

cfg = Config()

# --------- Save serializable config for reproducibility ---------
def config_to_serializable_dict(cfg):
    skip_types = (logging.Logger,)
    out = {}
    for k, v in cfg.__dict__.items():
        if k.startswith("_") or isinstance(v, skip_types) or callable(v):
            continue
        try:
            json.dumps(v)
            out[k] = v
        except Exception:
            continue
    return out
with open(os.path.join(cfg.OUTPUT_DIR, f'run_config_{cfg.TIMESTAMP}.json'), 'w') as f:
    json.dump(config_to_serializable_dict(cfg), f, indent=4)

# ---------------------------- Supervised Contrastive Loss ----------------------------
class SupConLoss(nn.Module):
    """
    Supervised Contrastive Loss for robust representation learning.
    """
    def __init__(self, temperature=0.07):
        super().__init__()
        self.temperature = temperature

    def forward(self, features, labels):
        # features: (bsz, feat_dim)
        # labels: (bsz)
        features = nn.functional.normalize(features, dim=1)
        similarity_matrix = torch.div(torch.matmul(features, features.T), self.temperature)
        labels = labels.contiguous().view(-1, 1)
        mask = torch.eq(labels, labels.T).float().to(features.device)
        logits_max, _ = torch.max(similarity_matrix, dim=1, keepdim=True)
        logits = similarity_matrix - logits_max.detach()
        exp_logits = torch.exp(logits) * (1 - torch.eye(labels.shape[0], device=features.device))
        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-12)
        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1).clamp(min=1)
        loss = -mean_log_prob_pos.mean()
        return loss

# ---------------------------- Augmentations ----------------------------
class PathologyAugment:
    @staticmethod
    def get_train_transform():
        return transforms.Compose([
            transforms.RandomResizedCrop(cfg.IMG_SIZE, scale=(0.6, 1.0), ratio=(0.8, 1.2)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomVerticalFlip(),
            transforms.ColorJitter(0.2, 0.2, 0.2, 0.05),
            transforms.RandomApply([transforms.GaussianBlur(3)], p=0.3),
            transforms.RandomApply([transforms.RandomRotation(15)], p=0.5),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
            transforms.RandomErasing(p=0.25, scale=(0.02, 0.2), ratio=(0.3, 3.3))
        ])
    @staticmethod
    def get_test_transform():
        return transforms.Compose([
            transforms.Resize(int(cfg.IMG_SIZE * 1.15)),
            transforms.CenterCrop(cfg.IMG_SIZE),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    @staticmethod
    def get_tta_transforms():
        base = PathologyAugment.get_test_transform()
        hflip = transforms.Compose([
            transforms.Resize(int(cfg.IMG_SIZE * 1.15)),
            transforms.CenterCrop(cfg.IMG_SIZE),
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        vflip = transforms.Compose([
            transforms.Resize(int(cfg.IMG_SIZE * 1.15)),
            transforms.CenterCrop(cfg.IMG_SIZE),
            transforms.RandomVerticalFlip(p=1.0),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        return [base, hflip, vflip]

# ---------------------------- Metrics Tracker ----------------------------
class MetricsTracker:
    def __init__(self):
        self.reset()
    def reset(self):
        self.losses, self.preds, self.targets, self.probs = [], [], [], []
    def update(self, loss, outputs, targets):
        self.losses.append(loss)
        probs = outputs.float().softmax(1).detach().cpu()
        self.probs.append(probs)
        self.preds.append(probs.argmax(1))
        self.targets.append(targets.detach().cpu())
    def compute(self):
        probs = torch.cat(self.probs).numpy()
        preds = torch.cat(self.preds).numpy()
        targets = torch.cat(self.targets).numpy()
        probs = probs / (probs.sum(axis=1, keepdims=True) + 1e-10)
        try:
            auc_score = roc_auc_score(targets, probs, multi_class='ovo')
        except Exception:
            auc_score = float('nan')
        return {
            "loss": np.mean(self.losses),
            "accuracy": accuracy_score(targets, preds),
            "balanced_accuracy": balanced_accuracy_score(targets, preds),
            "f1_macro": f1_score(targets, preds, average='macro'),
            "auc": auc_score,
            "targets": targets,
            "preds": preds,
            "probs": probs
        }

def create_weighted_sampler(dataset):
    class_counts = np.bincount([t for _, t in dataset.samples])
    weights = 1. / class_counts
    sample_weights = [weights[label] for _, label in dataset.samples]
    return WeightedRandomSampler(sample_weights, len(sample_weights))

def create_model():
    model = timm.create_model(
        cfg.MODEL_NAME, pretrained=True, num_classes=cfg.NUM_CLASSES,
        drop_rate=cfg.DROP_RATE, drop_path_rate=cfg.DROP_PATH_RATE, img_size=cfg.IMG_SIZE
    ).to(cfg.DEVICE)
    return model

def evaluate(model, loader, criterion=None):
    model.eval()
    tracker = MetricsTracker()
    with torch.inference_mode(), autocast(enabled=cfg.MIXED_PRECISION):
        for inputs, targets in tqdm(loader, desc="Evaluating", leave=False):
            inputs, targets = inputs.to(cfg.DEVICE), targets.to(cfg.DEVICE)
            outputs = model(inputs)
            loss = criterion(outputs, targets).item() if criterion else 0
            tracker.update(loss, outputs, targets)
    return tracker.compute()

def save_confusion_matrix(metrics, phase):
    cm = confusion_matrix(metrics['targets'], metrics['preds'])
    plt.figure(figsize=(7,6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
        xticklabels=cfg.CLASS_NAMES, yticklabels=cfg.CLASS_NAMES)
    plt.xlabel("Predicted"); plt.ylabel("True")
    plt.title(f"{phase} Confusion Matrix")
    plt.tight_layout()
    save_path = f"{cfg.OUTPUT_DIR}/{phase}_confusion_matrix_{cfg.TIMESTAMP}.png"
    plt.savefig(save_path); plt.close()

def save_classification_report(metrics, phase):
    report = classification_report(
        metrics['targets'], metrics['preds'], target_names=cfg.CLASS_NAMES, digits=4
    )
    save_path = f"{cfg.OUTPUT_DIR}/{phase}_report_{cfg.TIMESTAMP}.txt"
    with open(save_path, "w") as f:
        f.write(f"{phase} Classification Report:\n")
        f.write(report)
        f.write("\nBalanced Accuracy: {:.4f}\n".format(metrics['balanced_accuracy']))
        f.write("AUC: {:.4f}\n".format(metrics['auc']))
    print(f"\n{phase.capitalize()} Classification Report:\n{report}")

# ---------------------- Training Loop (Hybrid CE + SupCon) ----------------------
def train_epoch(model, loader, optimizer, criterion, scaler, mixup_fn, contrastive_loss, epoch):
    model.train()
    tracker = MetricsTracker()
    optimizer.zero_grad()
    for step, (inputs, targets) in enumerate(tqdm(loader, desc=f"Epoch {epoch+1}/{cfg.EPOCHS}", dynamic_ncols=True)):
        inputs, orig_targets = inputs.to(cfg.DEVICE), targets.to(cfg.DEVICE)
        if mixup_fn:
            inputs, mixed_targets = mixup_fn(inputs, orig_targets)
        else:
            mixed_targets = orig_targets

        with autocast(enabled=cfg.MIXED_PRECISION):
            # Forward
            outputs = model(inputs)
            ce_loss = criterion(outputs, mixed_targets)
            ce_loss = ce_loss / cfg.ACCUM_STEPS

            # Get features before classifier head (for Swin, use global avgpool of last hidden states)
            features = model.forward_features(inputs)
            if isinstance(features, (tuple, list)):  # sometimes Swin returns (x, ...)
                features = features[0]
            # global avgpool if needed
            if features.dim() > 2:
                features = features.mean(dim=(2, 3))
            con_loss = contrastive_loss(features, orig_targets)
            loss = (1 - cfg.CONTRASTIVE_LOSS_WEIGHT) * ce_loss + cfg.CONTRASTIVE_LOSS_WEIGHT * con_loss

        if scaler:
            scaler.scale(loss).backward()
            if (step + 1) % cfg.ACCUM_STEPS == 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.GRAD_CLIP)
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad()
        else:
            loss.backward()
            if (step + 1) % cfg.ACCUM_STEPS == 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.GRAD_CLIP)
                optimizer.step()
                optimizer.zero_grad()
        tracker.update(loss.item() * cfg.ACCUM_STEPS, outputs, orig_targets)
    return tracker.compute()

def tta_predict(model, dataset):
    tta_transforms = PathologyAugment.get_tta_transforms()
    loader = DataLoader(dataset, batch_size=cfg.VAL_BATCH_SIZE, shuffle=False, num_workers=cfg.NUM_WORKERS)
    all_probs = []
    model.eval()
    with torch.inference_mode(), autocast(enabled=cfg.MIXED_PRECISION):
        for tta_tf in tta_transforms:
            dataset.transform = tta_tf
            probs_run = []
            for inputs, _ in loader:
                inputs = inputs.to(cfg.DEVICE)
                outputs = model(inputs)
                probs = outputs.softmax(dim=1).detach().cpu().numpy()
                probs_run.append(probs)
            all_probs.append(np.concatenate(probs_run, axis=0))
    avg_probs = np.mean(np.stack(all_probs, axis=0), axis=0)
    targets = np.array([label for _, label in dataset.samples])
    preds = np.argmax(avg_probs, axis=1)
    return avg_probs, preds, targets

def main():
    cfg.logger.info(f"Starting Swin Transformer training at {cfg.TIMESTAMP}")
    train_ds = datasets.ImageFolder(cfg.DATA_PATHS['train'], PathologyAugment.get_train_transform())
    val_ds   = datasets.ImageFolder(cfg.DATA_PATHS['val'],   PathologyAugment.get_test_transform())
    test_ds  = datasets.ImageFolder(cfg.DATA_PATHS['test'],  PathologyAugment.get_test_transform())
    sampler = create_weighted_sampler(train_ds)
    train_loader = DataLoader(train_ds, batch_size=cfg.TRAIN_BATCH_SIZE, sampler=sampler, num_workers=cfg.NUM_WORKERS, pin_memory=True, drop_last=True)
    val_loader   = DataLoader(val_ds, batch_size=cfg.VAL_BATCH_SIZE, shuffle=False, num_workers=cfg.NUM_WORKERS, pin_memory=True)
    test_loader  = DataLoader(test_ds, batch_size=cfg.VAL_BATCH_SIZE, shuffle=False, num_workers=cfg.NUM_WORKERS, pin_memory=True)
    model = create_model()
    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)
    criterion = nn.CrossEntropyLoss(label_smoothing=cfg.LABEL_SMOOTHING)
    contrastive_loss = SupConLoss(temperature=0.07)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.EPOCHS)
    scaler = GradScaler() if cfg.MIXED_PRECISION else None
    mixup_fn = Mixup(
        mixup_alpha=cfg.MIXUP_ALPHA, cutmix_alpha=cfg.CUTMIX_ALPHA,
        label_smoothing=cfg.LABEL_SMOOTHING, num_classes=cfg.NUM_CLASSES
    ) if cfg.USE_MIXUP else None

    best_auc = 0; no_improve = 0
    for epoch in range(cfg.EPOCHS):
        train_metrics = train_epoch(model, train_loader, optimizer, criterion, scaler, mixup_fn, contrastive_loss, epoch)
        val_metrics = evaluate(model, val_loader, criterion)
        cfg.logger.info(f"Epoch {epoch+1} Train | Loss: {train_metrics['loss']:.4f} | Acc: {train_metrics['accuracy']:.4f} | AUC: {train_metrics['auc']:.4f}")
        cfg.logger.info(f"Epoch {epoch+1} Val   | Loss: {val_metrics['loss']:.4f} | Acc: {val_metrics['accuracy']:.4f} | AUC: {val_metrics['auc']:.4f}")
        scheduler.step()
        if val_metrics['auc'] > best_auc:
            best_auc = val_metrics['auc']
            no_improve = 0
            torch.save({
                'model': model.state_dict(),
                'optimizer': optimizer.state_dict(),
                'epoch': epoch,
                'config': config_to_serializable_dict(cfg)
            }, cfg.MODEL_SAVE)
            cfg.logger.info(f"Saved best model with AUC: {best_auc:.4f}")
        else:
            no_improve += 1
            if no_improve >= cfg.EARLY_STOP_PATIENCE:
                cfg.logger.info(f"Early stopping at epoch {epoch+1}")
                break
    # Load best weights
    model.load_state_dict(torch.load(cfg.MODEL_SAVE)['model'])

    # ----- Test & TTA -----
    if cfg.USE_TTA:
        avg_probs, preds, targets = tta_predict(model, test_ds)
        f1 = f1_score(targets, preds, average='macro')
        auc = roc_auc_score(targets, avg_probs, multi_class='ovo')
        print(f"\nTest (TTA) F1 Macro: {f1:.4f} | AUC: {auc:.4f}")
        print(classification_report(targets, preds, target_names=cfg.CLASS_NAMES))
        save_confusion_matrix({'targets': targets, 'preds': preds}, "test_tta")
        save_classification_report({'targets': targets, 'preds': preds, 'balanced_accuracy': balanced_accuracy_score(targets, preds), 'auc': auc}, "test_tta")
    else:
        test_metrics = evaluate(model, test_loader, criterion)
        save_confusion_matrix(test_metrics, "test")
        save_classification_report(test_metrics, "test")
        print(f"\nFinal Test Accuracy: {test_metrics['accuracy']:.4f}")
        print(f"F1 Macro: {test_metrics['f1_macro']:.4f}")
        print(f"AUC: {test_metrics['auc']:.4f}")

    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

if __name__ == "__main__":
    main()
